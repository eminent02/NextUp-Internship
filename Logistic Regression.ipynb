{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7418</td>\n",
       "      <td>-0.201182</td>\n",
       "      <td>-1.785541</td>\n",
       "      <td>-1.386380</td>\n",
       "      <td>2.199543</td>\n",
       "      <td>1.525807</td>\n",
       "      <td>2.954481</td>\n",
       "      <td>0.264425</td>\n",
       "      <td>-0.239757</td>\n",
       "      <td>0.953239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131055</td>\n",
       "      <td>0.662084</td>\n",
       "      <td>-0.086671</td>\n",
       "      <td>-0.118522</td>\n",
       "      <td>0.700997</td>\n",
       "      <td>0.380318</td>\n",
       "      <td>0.197355</td>\n",
       "      <td>-0.896647</td>\n",
       "      <td>-0.409293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154234</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0.128667</td>\n",
       "      <td>-23.984747</td>\n",
       "      <td>16.697832</td>\n",
       "      <td>-22.209875</td>\n",
       "      <td>9.584969</td>\n",
       "      <td>-16.230439</td>\n",
       "      <td>2.596333</td>\n",
       "      <td>-33.239328</td>\n",
       "      <td>...</td>\n",
       "      <td>5.804551</td>\n",
       "      <td>-12.615023</td>\n",
       "      <td>5.774087</td>\n",
       "      <td>2.750221</td>\n",
       "      <td>0.513411</td>\n",
       "      <td>-1.608804</td>\n",
       "      <td>-0.459624</td>\n",
       "      <td>-4.626127</td>\n",
       "      <td>-0.334561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173753</td>\n",
       "      <td>-0.209898</td>\n",
       "      <td>0.564650</td>\n",
       "      <td>0.345932</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.249973</td>\n",
       "      <td>-2.121791</td>\n",
       "      <td>0.461026</td>\n",
       "      <td>-0.265107</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177209</td>\n",
       "      <td>0.557694</td>\n",
       "      <td>1.489021</td>\n",
       "      <td>-0.219031</td>\n",
       "      <td>0.356435</td>\n",
       "      <td>0.070467</td>\n",
       "      <td>-0.027019</td>\n",
       "      <td>-0.007897</td>\n",
       "      <td>-0.016354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222133</td>\n",
       "      <td>0.225693</td>\n",
       "      <td>1.011331</td>\n",
       "      <td>-3.613850</td>\n",
       "      <td>-0.922136</td>\n",
       "      <td>-4.749887</td>\n",
       "      <td>3.373001</td>\n",
       "      <td>-0.545207</td>\n",
       "      <td>-1.171301</td>\n",
       "      <td>-4.172315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320541</td>\n",
       "      <td>0.786787</td>\n",
       "      <td>0.893065</td>\n",
       "      <td>1.034907</td>\n",
       "      <td>0.097671</td>\n",
       "      <td>-1.345551</td>\n",
       "      <td>-0.788329</td>\n",
       "      <td>1.055442</td>\n",
       "      <td>0.099971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15506</td>\n",
       "      <td>0.046539</td>\n",
       "      <td>-1.430146</td>\n",
       "      <td>-21.885434</td>\n",
       "      <td>12.930505</td>\n",
       "      <td>-24.098872</td>\n",
       "      <td>6.203314</td>\n",
       "      <td>-16.466099</td>\n",
       "      <td>-4.459842</td>\n",
       "      <td>-16.519836</td>\n",
       "      <td>...</td>\n",
       "      <td>1.611998</td>\n",
       "      <td>1.762232</td>\n",
       "      <td>-1.579055</td>\n",
       "      <td>-0.951043</td>\n",
       "      <td>0.134565</td>\n",
       "      <td>1.507110</td>\n",
       "      <td>-0.222671</td>\n",
       "      <td>1.527655</td>\n",
       "      <td>0.453699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  scaled_amount  scaled_time         V1         V2         V3  \\\n",
       "0        7418      -0.201182    -1.785541  -1.386380   2.199543   1.525807   \n",
       "1      154234      -0.349231     0.128667 -23.984747  16.697832 -22.209875   \n",
       "2      173753      -0.209898     0.564650   0.345932  -0.024238  -0.249973   \n",
       "3      222133       0.225693     1.011331  -3.613850  -0.922136  -4.749887   \n",
       "4       15506       0.046539    -1.430146 -21.885434  12.930505 -24.098872   \n",
       "\n",
       "         V4         V5        V6         V7  ...       V20        V21  \\\n",
       "0  2.954481   0.264425 -0.239757   0.953239  ... -0.131055   0.662084   \n",
       "1  9.584969 -16.230439  2.596333 -33.239328  ...  5.804551 -12.615023   \n",
       "2 -2.121791   0.461026 -0.265107   0.399168  ...  0.177209   0.557694   \n",
       "3  3.373001  -0.545207 -1.171301  -4.172315  ... -0.320541   0.786787   \n",
       "4  6.203314 -16.466099 -4.459842 -16.519836  ...  1.611998   1.762232   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.086671 -0.118522  0.700997  0.380318  0.197355 -0.896647 -0.409293      0  \n",
       "1  5.774087  2.750221  0.513411 -1.608804 -0.459624 -4.626127 -0.334561      1  \n",
       "2  1.489021 -0.219031  0.356435  0.070467 -0.027019 -0.007897 -0.016354      0  \n",
       "3  0.893065  1.034907  0.097671 -1.345551 -0.788329  1.055442  0.099971      1  \n",
       "4 -1.579055 -0.951043  0.134565  1.507110 -0.222671  1.527655  0.453699      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.201182</td>\n",
       "      <td>-1.785541</td>\n",
       "      <td>-1.386380</td>\n",
       "      <td>2.199543</td>\n",
       "      <td>1.525807</td>\n",
       "      <td>2.954481</td>\n",
       "      <td>0.264425</td>\n",
       "      <td>-0.239757</td>\n",
       "      <td>0.953239</td>\n",
       "      <td>-1.336626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131055</td>\n",
       "      <td>0.662084</td>\n",
       "      <td>-0.086671</td>\n",
       "      <td>-0.118522</td>\n",
       "      <td>0.700997</td>\n",
       "      <td>0.380318</td>\n",
       "      <td>0.197355</td>\n",
       "      <td>-0.896647</td>\n",
       "      <td>-0.409293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0.128667</td>\n",
       "      <td>-23.984747</td>\n",
       "      <td>16.697832</td>\n",
       "      <td>-22.209875</td>\n",
       "      <td>9.584969</td>\n",
       "      <td>-16.230439</td>\n",
       "      <td>2.596333</td>\n",
       "      <td>-33.239328</td>\n",
       "      <td>-21.560039</td>\n",
       "      <td>...</td>\n",
       "      <td>5.804551</td>\n",
       "      <td>-12.615023</td>\n",
       "      <td>5.774087</td>\n",
       "      <td>2.750221</td>\n",
       "      <td>0.513411</td>\n",
       "      <td>-1.608804</td>\n",
       "      <td>-0.459624</td>\n",
       "      <td>-4.626127</td>\n",
       "      <td>-0.334561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.209898</td>\n",
       "      <td>0.564650</td>\n",
       "      <td>0.345932</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.249973</td>\n",
       "      <td>-2.121791</td>\n",
       "      <td>0.461026</td>\n",
       "      <td>-0.265107</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>-0.121305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177209</td>\n",
       "      <td>0.557694</td>\n",
       "      <td>1.489021</td>\n",
       "      <td>-0.219031</td>\n",
       "      <td>0.356435</td>\n",
       "      <td>0.070467</td>\n",
       "      <td>-0.027019</td>\n",
       "      <td>-0.007897</td>\n",
       "      <td>-0.016354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225693</td>\n",
       "      <td>1.011331</td>\n",
       "      <td>-3.613850</td>\n",
       "      <td>-0.922136</td>\n",
       "      <td>-4.749887</td>\n",
       "      <td>3.373001</td>\n",
       "      <td>-0.545207</td>\n",
       "      <td>-1.171301</td>\n",
       "      <td>-4.172315</td>\n",
       "      <td>1.517016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320541</td>\n",
       "      <td>0.786787</td>\n",
       "      <td>0.893065</td>\n",
       "      <td>1.034907</td>\n",
       "      <td>0.097671</td>\n",
       "      <td>-1.345551</td>\n",
       "      <td>-0.788329</td>\n",
       "      <td>1.055442</td>\n",
       "      <td>0.099971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046539</td>\n",
       "      <td>-1.430146</td>\n",
       "      <td>-21.885434</td>\n",
       "      <td>12.930505</td>\n",
       "      <td>-24.098872</td>\n",
       "      <td>6.203314</td>\n",
       "      <td>-16.466099</td>\n",
       "      <td>-4.459842</td>\n",
       "      <td>-16.519836</td>\n",
       "      <td>14.535565</td>\n",
       "      <td>...</td>\n",
       "      <td>1.611998</td>\n",
       "      <td>1.762232</td>\n",
       "      <td>-1.579055</td>\n",
       "      <td>-0.951043</td>\n",
       "      <td>0.134565</td>\n",
       "      <td>1.507110</td>\n",
       "      <td>-0.222671</td>\n",
       "      <td>1.527655</td>\n",
       "      <td>0.453699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time         V1         V2         V3        V4  \\\n",
       "0      -0.201182    -1.785541  -1.386380   2.199543   1.525807  2.954481   \n",
       "1      -0.349231     0.128667 -23.984747  16.697832 -22.209875  9.584969   \n",
       "2      -0.209898     0.564650   0.345932  -0.024238  -0.249973 -2.121791   \n",
       "3       0.225693     1.011331  -3.613850  -0.922136  -4.749887  3.373001   \n",
       "4       0.046539    -1.430146 -21.885434  12.930505 -24.098872  6.203314   \n",
       "\n",
       "          V5        V6         V7         V8  ...       V20        V21  \\\n",
       "0   0.264425 -0.239757   0.953239  -1.336626  ... -0.131055   0.662084   \n",
       "1 -16.230439  2.596333 -33.239328 -21.560039  ...  5.804551 -12.615023   \n",
       "2   0.461026 -0.265107   0.399168  -0.121305  ...  0.177209   0.557694   \n",
       "3  -0.545207 -1.171301  -4.172315   1.517016  ... -0.320541   0.786787   \n",
       "4 -16.466099 -4.459842 -16.519836  14.535565  ...  1.611998   1.762232   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.086671 -0.118522  0.700997  0.380318  0.197355 -0.896647 -0.409293      0  \n",
       "1  5.774087  2.750221  0.513411 -1.608804 -0.459624 -4.626127 -0.334561      1  \n",
       "2  1.489021 -0.219031  0.356435  0.070467 -0.027019 -0.007897 -0.016354      0  \n",
       "3  0.893065  1.034907  0.097671 -1.345551 -0.788329  1.055442  0.099971      1  \n",
       "4 -1.579055 -0.951043  0.134565  1.507110 -0.222671  1.527655  0.453699      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[ :, :-1].values\n",
    "y = df.iloc[ :, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 10000, random_state = 0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[396   6]\n",
      " [ 33 352]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504447268106735"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86,  4],\n",
       "       [10, 97]], dtype=int64)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289340101522843"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV ( cross-validation estimator)\n",
    "#### Highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  2],\n",
       "       [ 9, 98]], dtype=int64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441624365482234"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression with MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 10000, random_state = 0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90,  0],\n",
       "       [15, 92]], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9238578680203046"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV with MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87,  3],\n",
       "       [10, 97]], dtype=int64)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.934010152284264"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression with  PowerTransformer Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "scalerPT = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "scalerPT.fit(X_train)\n",
    "X_train = scalerPT.transform(X_train)\n",
    "X_test = scalerPT.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 10000, random_state = 0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  2],\n",
       "       [10, 97]], dtype=int64)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9390862944162437"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV with  PowerTransformer Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  2],\n",
       "       [10, 97]], dtype=int64)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9390862944162437"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV ( dropped scaled_time column ) \n",
    "#### Makes no difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[ :, ~df.columns.isin(['scaled_time', 'Class'])]#.values\n",
    "y = df.iloc[ :, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.201182</td>\n",
       "      <td>-1.386380</td>\n",
       "      <td>2.199543</td>\n",
       "      <td>1.525807</td>\n",
       "      <td>2.954481</td>\n",
       "      <td>0.264425</td>\n",
       "      <td>-0.239757</td>\n",
       "      <td>0.953239</td>\n",
       "      <td>-1.336626</td>\n",
       "      <td>-0.447353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649332</td>\n",
       "      <td>-0.131055</td>\n",
       "      <td>0.662084</td>\n",
       "      <td>-0.086671</td>\n",
       "      <td>-0.118522</td>\n",
       "      <td>0.700997</td>\n",
       "      <td>0.380318</td>\n",
       "      <td>0.197355</td>\n",
       "      <td>-0.896647</td>\n",
       "      <td>-0.409293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-23.984747</td>\n",
       "      <td>16.697832</td>\n",
       "      <td>-22.209875</td>\n",
       "      <td>9.584969</td>\n",
       "      <td>-16.230439</td>\n",
       "      <td>2.596333</td>\n",
       "      <td>-33.239328</td>\n",
       "      <td>-21.560039</td>\n",
       "      <td>-10.842526</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.243285</td>\n",
       "      <td>5.804551</td>\n",
       "      <td>-12.615023</td>\n",
       "      <td>5.774087</td>\n",
       "      <td>2.750221</td>\n",
       "      <td>0.513411</td>\n",
       "      <td>-1.608804</td>\n",
       "      <td>-0.459624</td>\n",
       "      <td>-4.626127</td>\n",
       "      <td>-0.334561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.209898</td>\n",
       "      <td>0.345932</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.249973</td>\n",
       "      <td>-2.121791</td>\n",
       "      <td>0.461026</td>\n",
       "      <td>-0.265107</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>-0.121305</td>\n",
       "      <td>-1.544817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632515</td>\n",
       "      <td>0.177209</td>\n",
       "      <td>0.557694</td>\n",
       "      <td>1.489021</td>\n",
       "      <td>-0.219031</td>\n",
       "      <td>0.356435</td>\n",
       "      <td>0.070467</td>\n",
       "      <td>-0.027019</td>\n",
       "      <td>-0.007897</td>\n",
       "      <td>-0.016354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225693</td>\n",
       "      <td>-3.613850</td>\n",
       "      <td>-0.922136</td>\n",
       "      <td>-4.749887</td>\n",
       "      <td>3.373001</td>\n",
       "      <td>-0.545207</td>\n",
       "      <td>-1.171301</td>\n",
       "      <td>-4.172315</td>\n",
       "      <td>1.517016</td>\n",
       "      <td>-1.775833</td>\n",
       "      <td>...</td>\n",
       "      <td>1.987386</td>\n",
       "      <td>-0.320541</td>\n",
       "      <td>0.786787</td>\n",
       "      <td>0.893065</td>\n",
       "      <td>1.034907</td>\n",
       "      <td>0.097671</td>\n",
       "      <td>-1.345551</td>\n",
       "      <td>-0.788329</td>\n",
       "      <td>1.055442</td>\n",
       "      <td>0.099971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046539</td>\n",
       "      <td>-21.885434</td>\n",
       "      <td>12.930505</td>\n",
       "      <td>-24.098872</td>\n",
       "      <td>6.203314</td>\n",
       "      <td>-16.466099</td>\n",
       "      <td>-4.459842</td>\n",
       "      <td>-16.519836</td>\n",
       "      <td>14.535565</td>\n",
       "      <td>-3.897022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.104355</td>\n",
       "      <td>1.611998</td>\n",
       "      <td>1.762232</td>\n",
       "      <td>-1.579055</td>\n",
       "      <td>-0.951043</td>\n",
       "      <td>0.134565</td>\n",
       "      <td>1.507110</td>\n",
       "      <td>-0.222671</td>\n",
       "      <td>1.527655</td>\n",
       "      <td>0.453699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-0.321245</td>\n",
       "      <td>0.385108</td>\n",
       "      <td>1.217620</td>\n",
       "      <td>-1.953872</td>\n",
       "      <td>2.087076</td>\n",
       "      <td>-1.144225</td>\n",
       "      <td>-0.576888</td>\n",
       "      <td>-2.582865</td>\n",
       "      <td>0.643230</td>\n",
       "      <td>-1.191233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572791</td>\n",
       "      <td>0.380545</td>\n",
       "      <td>0.594623</td>\n",
       "      <td>0.372144</td>\n",
       "      <td>-0.310456</td>\n",
       "      <td>-0.624065</td>\n",
       "      <td>0.840216</td>\n",
       "      <td>-0.159452</td>\n",
       "      <td>0.599482</td>\n",
       "      <td>0.288916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0.378275</td>\n",
       "      <td>3.914797</td>\n",
       "      <td>-5.726872</td>\n",
       "      <td>6.094141</td>\n",
       "      <td>1.698875</td>\n",
       "      <td>-2.807314</td>\n",
       "      <td>-0.591118</td>\n",
       "      <td>-0.123496</td>\n",
       "      <td>-2.530713</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.005477</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.149896</td>\n",
       "      <td>-0.601967</td>\n",
       "      <td>-0.613724</td>\n",
       "      <td>-0.403114</td>\n",
       "      <td>1.568445</td>\n",
       "      <td>0.521884</td>\n",
       "      <td>0.527938</td>\n",
       "      <td>0.411910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.093314</td>\n",
       "      <td>-1.608599</td>\n",
       "      <td>2.492957</td>\n",
       "      <td>1.949613</td>\n",
       "      <td>4.522021</td>\n",
       "      <td>-0.854594</td>\n",
       "      <td>1.289795</td>\n",
       "      <td>-0.739294</td>\n",
       "      <td>-3.242835</td>\n",
       "      <td>-1.287922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556060</td>\n",
       "      <td>-0.567406</td>\n",
       "      <td>3.463274</td>\n",
       "      <td>0.251718</td>\n",
       "      <td>0.231933</td>\n",
       "      <td>0.880244</td>\n",
       "      <td>-0.554212</td>\n",
       "      <td>0.434216</td>\n",
       "      <td>-0.122083</td>\n",
       "      <td>0.202091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.233487</td>\n",
       "      <td>-0.734303</td>\n",
       "      <td>0.435519</td>\n",
       "      <td>-0.530866</td>\n",
       "      <td>-0.471120</td>\n",
       "      <td>0.643214</td>\n",
       "      <td>0.713832</td>\n",
       "      <td>-1.234572</td>\n",
       "      <td>-2.551412</td>\n",
       "      <td>-2.057724</td>\n",
       "      <td>...</td>\n",
       "      <td>2.502027</td>\n",
       "      <td>0.864536</td>\n",
       "      <td>-1.004877</td>\n",
       "      <td>1.150354</td>\n",
       "      <td>-0.152555</td>\n",
       "      <td>-1.386745</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.219146</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>0.158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.038623</td>\n",
       "      <td>1.227614</td>\n",
       "      <td>-0.668974</td>\n",
       "      <td>-0.271785</td>\n",
       "      <td>-0.589440</td>\n",
       "      <td>-0.604795</td>\n",
       "      <td>-0.350285</td>\n",
       "      <td>-0.486365</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>-0.794944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190121</td>\n",
       "      <td>0.273799</td>\n",
       "      <td>-0.026055</td>\n",
       "      <td>-0.295255</td>\n",
       "      <td>-0.180459</td>\n",
       "      <td>-0.436539</td>\n",
       "      <td>0.494649</td>\n",
       "      <td>-0.283738</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.035075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     scaled_amount         V1         V2         V3        V4         V5  \\\n",
       "0        -0.201182  -1.386380   2.199543   1.525807  2.954481   0.264425   \n",
       "1        -0.349231 -23.984747  16.697832 -22.209875  9.584969 -16.230439   \n",
       "2        -0.209898   0.345932  -0.024238  -0.249973 -2.121791   0.461026   \n",
       "3         0.225693  -3.613850  -0.922136  -4.749887  3.373001  -0.545207   \n",
       "4         0.046539 -21.885434  12.930505 -24.098872  6.203314 -16.466099   \n",
       "..             ...        ...        ...        ...       ...        ...   \n",
       "979      -0.321245   0.385108   1.217620  -1.953872  2.087076  -1.144225   \n",
       "980      -0.349231   0.378275   3.914797  -5.726872  6.094141   1.698875   \n",
       "981      -0.093314  -1.608599   2.492957   1.949613  4.522021  -0.854594   \n",
       "982      -0.233487  -0.734303   0.435519  -0.530866 -0.471120   0.643214   \n",
       "983       0.038623   1.227614  -0.668974  -0.271785 -0.589440  -0.604795   \n",
       "\n",
       "           V6         V7         V8         V9  ...       V19       V20  \\\n",
       "0   -0.239757   0.953239  -1.336626  -0.447353  ...  0.649332 -0.131055   \n",
       "1    2.596333 -33.239328 -21.560039 -10.842526  ... -1.243285  5.804551   \n",
       "2   -0.265107   0.399168  -0.121305  -1.544817  ...  0.632515  0.177209   \n",
       "3   -1.171301  -4.172315   1.517016  -1.775833  ...  1.987386 -0.320541   \n",
       "4   -4.459842 -16.519836  14.535565  -3.897022  ...  1.104355  1.611998   \n",
       "..        ...        ...        ...        ...  ...       ...       ...   \n",
       "979 -0.576888  -2.582865   0.643230  -1.191233  ...  0.572791  0.380545   \n",
       "980 -2.807314  -0.591118  -0.123496  -2.530713  ... -2.005477  0.440439   \n",
       "981  1.289795  -0.739294  -3.242835  -1.287922  ...  0.556060 -0.567406   \n",
       "982  0.713832  -1.234572  -2.551412  -2.057724  ...  2.502027  0.864536   \n",
       "983 -0.350285  -0.486365  -0.010809  -0.794944  ...  1.190121  0.273799   \n",
       "\n",
       "           V21       V22       V23       V24       V25       V26       V27  \\\n",
       "0     0.662084 -0.086671 -0.118522  0.700997  0.380318  0.197355 -0.896647   \n",
       "1   -12.615023  5.774087  2.750221  0.513411 -1.608804 -0.459624 -4.626127   \n",
       "2     0.557694  1.489021 -0.219031  0.356435  0.070467 -0.027019 -0.007897   \n",
       "3     0.786787  0.893065  1.034907  0.097671 -1.345551 -0.788329  1.055442   \n",
       "4     1.762232 -1.579055 -0.951043  0.134565  1.507110 -0.222671  1.527655   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "979   0.594623  0.372144 -0.310456 -0.624065  0.840216 -0.159452  0.599482   \n",
       "980   0.149896 -0.601967 -0.613724 -0.403114  1.568445  0.521884  0.527938   \n",
       "981   3.463274  0.251718  0.231933  0.880244 -0.554212  0.434216 -0.122083   \n",
       "982  -1.004877  1.150354 -0.152555 -1.386745  0.004716  0.219146 -0.058257   \n",
       "983  -0.026055 -0.295255 -0.180459 -0.436539  0.494649 -0.283738 -0.001128   \n",
       "\n",
       "          V28  \n",
       "0   -0.409293  \n",
       "1   -0.334561  \n",
       "2   -0.016354  \n",
       "3    0.099971  \n",
       "4    0.453699  \n",
       "..        ...  \n",
       "979  0.288916  \n",
       "980  0.411910  \n",
       "981  0.202091  \n",
       "982  0.158048  \n",
       "983  0.035075  \n",
       "\n",
       "[984 rows x 29 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  2],\n",
       "       [ 9, 98]], dtype=int64)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441624365482234"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV ( dropped V20 to V28 column ) \n",
    "#### Drop in accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[ :, ~df.columns.isin(['V20', 'V21', 'V22', 'V23', 'V24','V25', 'V26','V27', 'V28','Class'])]#.values\n",
    "y = df.iloc[ :, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.201182</td>\n",
       "      <td>-1.785541</td>\n",
       "      <td>-1.386380</td>\n",
       "      <td>2.199543</td>\n",
       "      <td>1.525807</td>\n",
       "      <td>2.954481</td>\n",
       "      <td>0.264425</td>\n",
       "      <td>-0.239757</td>\n",
       "      <td>0.953239</td>\n",
       "      <td>-1.336626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922799</td>\n",
       "      <td>1.011378</td>\n",
       "      <td>-2.273314</td>\n",
       "      <td>2.867908</td>\n",
       "      <td>1.498809</td>\n",
       "      <td>0.152471</td>\n",
       "      <td>-0.664465</td>\n",
       "      <td>0.951424</td>\n",
       "      <td>-0.147900</td>\n",
       "      <td>0.649332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0.128667</td>\n",
       "      <td>-23.984747</td>\n",
       "      <td>16.697832</td>\n",
       "      <td>-22.209875</td>\n",
       "      <td>9.584969</td>\n",
       "      <td>-16.230439</td>\n",
       "      <td>2.596333</td>\n",
       "      <td>-33.239328</td>\n",
       "      <td>-21.560039</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.836149</td>\n",
       "      <td>3.223233</td>\n",
       "      <td>-10.895134</td>\n",
       "      <td>-1.523452</td>\n",
       "      <td>0.116303</td>\n",
       "      <td>-3.098805</td>\n",
       "      <td>-7.606425</td>\n",
       "      <td>-18.108261</td>\n",
       "      <td>-7.511866</td>\n",
       "      <td>-1.243285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.209898</td>\n",
       "      <td>0.564650</td>\n",
       "      <td>0.345932</td>\n",
       "      <td>-0.024238</td>\n",
       "      <td>-0.249973</td>\n",
       "      <td>-2.121791</td>\n",
       "      <td>0.461026</td>\n",
       "      <td>-0.265107</td>\n",
       "      <td>0.399168</td>\n",
       "      <td>-0.121305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337301</td>\n",
       "      <td>0.620181</td>\n",
       "      <td>0.076565</td>\n",
       "      <td>1.121529</td>\n",
       "      <td>-0.170874</td>\n",
       "      <td>-0.812162</td>\n",
       "      <td>1.272336</td>\n",
       "      <td>-0.488331</td>\n",
       "      <td>-0.567751</td>\n",
       "      <td>0.632515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225693</td>\n",
       "      <td>1.011331</td>\n",
       "      <td>-3.613850</td>\n",
       "      <td>-0.922136</td>\n",
       "      <td>-4.749887</td>\n",
       "      <td>3.373001</td>\n",
       "      <td>-0.545207</td>\n",
       "      <td>-1.171301</td>\n",
       "      <td>-4.172315</td>\n",
       "      <td>1.517016</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.754054</td>\n",
       "      <td>2.731576</td>\n",
       "      <td>-3.489375</td>\n",
       "      <td>1.547380</td>\n",
       "      <td>-4.571268</td>\n",
       "      <td>-0.517959</td>\n",
       "      <td>-4.239087</td>\n",
       "      <td>-9.250635</td>\n",
       "      <td>-2.434828</td>\n",
       "      <td>1.987386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046539</td>\n",
       "      <td>-1.430146</td>\n",
       "      <td>-21.885434</td>\n",
       "      <td>12.930505</td>\n",
       "      <td>-24.098872</td>\n",
       "      <td>6.203314</td>\n",
       "      <td>-16.466099</td>\n",
       "      <td>-4.459842</td>\n",
       "      <td>-16.519836</td>\n",
       "      <td>14.535565</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.650758</td>\n",
       "      <td>5.375434</td>\n",
       "      <td>-7.567214</td>\n",
       "      <td>0.461808</td>\n",
       "      <td>-7.827891</td>\n",
       "      <td>-0.022815</td>\n",
       "      <td>-6.578042</td>\n",
       "      <td>-13.002459</td>\n",
       "      <td>-4.884467</td>\n",
       "      <td>1.104355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-0.321245</td>\n",
       "      <td>-0.871016</td>\n",
       "      <td>0.385108</td>\n",
       "      <td>1.217620</td>\n",
       "      <td>-1.953872</td>\n",
       "      <td>2.087076</td>\n",
       "      <td>-1.144225</td>\n",
       "      <td>-0.576888</td>\n",
       "      <td>-2.582865</td>\n",
       "      <td>0.643230</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.095094</td>\n",
       "      <td>2.821145</td>\n",
       "      <td>-3.100546</td>\n",
       "      <td>0.146199</td>\n",
       "      <td>-4.510124</td>\n",
       "      <td>0.574490</td>\n",
       "      <td>-2.123463</td>\n",
       "      <td>-6.053319</td>\n",
       "      <td>-0.706376</td>\n",
       "      <td>0.572791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-0.349231</td>\n",
       "      <td>-1.763009</td>\n",
       "      <td>0.378275</td>\n",
       "      <td>3.914797</td>\n",
       "      <td>-5.726872</td>\n",
       "      <td>6.094141</td>\n",
       "      <td>1.698875</td>\n",
       "      <td>-2.807314</td>\n",
       "      <td>-0.591118</td>\n",
       "      <td>-0.123496</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.153095</td>\n",
       "      <td>4.654088</td>\n",
       "      <td>-7.839539</td>\n",
       "      <td>1.371819</td>\n",
       "      <td>-9.634690</td>\n",
       "      <td>-0.739597</td>\n",
       "      <td>-0.663204</td>\n",
       "      <td>0.891935</td>\n",
       "      <td>0.978676</td>\n",
       "      <td>-2.005477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.093314</td>\n",
       "      <td>-0.147424</td>\n",
       "      <td>-1.608599</td>\n",
       "      <td>2.492957</td>\n",
       "      <td>1.949613</td>\n",
       "      <td>4.522021</td>\n",
       "      <td>-0.854594</td>\n",
       "      <td>1.289795</td>\n",
       "      <td>-0.739294</td>\n",
       "      <td>-3.242835</td>\n",
       "      <td>...</td>\n",
       "      <td>1.981092</td>\n",
       "      <td>-0.253495</td>\n",
       "      <td>0.469117</td>\n",
       "      <td>1.252766</td>\n",
       "      <td>-0.386521</td>\n",
       "      <td>0.461747</td>\n",
       "      <td>-0.357709</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>0.028496</td>\n",
       "      <td>0.556060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.233487</td>\n",
       "      <td>-0.405531</td>\n",
       "      <td>-0.734303</td>\n",
       "      <td>0.435519</td>\n",
       "      <td>-0.530866</td>\n",
       "      <td>-0.471120</td>\n",
       "      <td>0.643214</td>\n",
       "      <td>0.713832</td>\n",
       "      <td>-1.234572</td>\n",
       "      <td>-2.551412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166831</td>\n",
       "      <td>0.567552</td>\n",
       "      <td>-0.858060</td>\n",
       "      <td>-0.448068</td>\n",
       "      <td>-0.264936</td>\n",
       "      <td>0.888863</td>\n",
       "      <td>0.838121</td>\n",
       "      <td>1.425060</td>\n",
       "      <td>-0.169664</td>\n",
       "      <td>2.502027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.038623</td>\n",
       "      <td>-0.612488</td>\n",
       "      <td>1.227614</td>\n",
       "      <td>-0.668974</td>\n",
       "      <td>-0.271785</td>\n",
       "      <td>-0.589440</td>\n",
       "      <td>-0.604795</td>\n",
       "      <td>-0.350285</td>\n",
       "      <td>-0.486365</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>0.881268</td>\n",
       "      <td>-0.324704</td>\n",
       "      <td>-0.263264</td>\n",
       "      <td>-1.112735</td>\n",
       "      <td>-0.540850</td>\n",
       "      <td>1.533411</td>\n",
       "      <td>0.831443</td>\n",
       "      <td>-0.473347</td>\n",
       "      <td>1.190121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     scaled_amount  scaled_time         V1         V2         V3        V4  \\\n",
       "0        -0.201182    -1.785541  -1.386380   2.199543   1.525807  2.954481   \n",
       "1        -0.349231     0.128667 -23.984747  16.697832 -22.209875  9.584969   \n",
       "2        -0.209898     0.564650   0.345932  -0.024238  -0.249973 -2.121791   \n",
       "3         0.225693     1.011331  -3.613850  -0.922136  -4.749887  3.373001   \n",
       "4         0.046539    -1.430146 -21.885434  12.930505 -24.098872  6.203314   \n",
       "..             ...          ...        ...        ...        ...       ...   \n",
       "979      -0.321245    -0.871016   0.385108   1.217620  -1.953872  2.087076   \n",
       "980      -0.349231    -1.763009   0.378275   3.914797  -5.726872  6.094141   \n",
       "981      -0.093314    -0.147424  -1.608599   2.492957   1.949613  4.522021   \n",
       "982      -0.233487    -0.405531  -0.734303   0.435519  -0.530866 -0.471120   \n",
       "983       0.038623    -0.612488   1.227614  -0.668974  -0.271785 -0.589440   \n",
       "\n",
       "            V5        V6         V7         V8  ...        V10       V11  \\\n",
       "0     0.264425 -0.239757   0.953239  -1.336626  ...   0.922799  1.011378   \n",
       "1   -16.230439  2.596333 -33.239328 -21.560039  ... -19.836149  3.223233   \n",
       "2     0.461026 -0.265107   0.399168  -0.121305  ...   0.337301  0.620181   \n",
       "3    -0.545207 -1.171301  -4.172315   1.517016  ...  -3.754054  2.731576   \n",
       "4   -16.466099 -4.459842 -16.519836  14.535565  ...  -8.650758  5.375434   \n",
       "..         ...       ...        ...        ...  ...        ...       ...   \n",
       "979  -1.144225 -0.576888  -2.582865   0.643230  ...  -3.095094  2.821145   \n",
       "980   1.698875 -2.807314  -0.591118  -0.123496  ...  -5.153095  4.654088   \n",
       "981  -0.854594  1.289795  -0.739294  -3.242835  ...   1.981092 -0.253495   \n",
       "982   0.643214  0.713832  -1.234572  -2.551412  ...   0.166831  0.567552   \n",
       "983  -0.604795 -0.350285  -0.486365  -0.010809  ...   0.264545  0.881268   \n",
       "\n",
       "           V12       V13       V14       V15       V16        V17       V18  \\\n",
       "0    -2.273314  2.867908  1.498809  0.152471 -0.664465   0.951424 -0.147900   \n",
       "1   -10.895134 -1.523452  0.116303 -3.098805 -7.606425 -18.108261 -7.511866   \n",
       "2     0.076565  1.121529 -0.170874 -0.812162  1.272336  -0.488331 -0.567751   \n",
       "3    -3.489375  1.547380 -4.571268 -0.517959 -4.239087  -9.250635 -2.434828   \n",
       "4    -7.567214  0.461808 -7.827891 -0.022815 -6.578042 -13.002459 -4.884467   \n",
       "..         ...       ...       ...       ...       ...        ...       ...   \n",
       "979  -3.100546  0.146199 -4.510124  0.574490 -2.123463  -6.053319 -0.706376   \n",
       "980  -7.839539  1.371819 -9.634690 -0.739597 -0.663204   0.891935  0.978676   \n",
       "981   0.469117  1.252766 -0.386521  0.461747 -0.357709   0.627745  0.028496   \n",
       "982  -0.858060 -0.448068 -0.264936  0.888863  0.838121   1.425060 -0.169664   \n",
       "983  -0.324704 -0.263264 -1.112735 -0.540850  1.533411   0.831443 -0.473347   \n",
       "\n",
       "          V19  \n",
       "0    0.649332  \n",
       "1   -1.243285  \n",
       "2    0.632515  \n",
       "3    1.987386  \n",
       "4    1.104355  \n",
       "..        ...  \n",
       "979  0.572791  \n",
       "980 -2.005477  \n",
       "981  0.556060  \n",
       "982  2.502027  \n",
       "983  1.190121  \n",
       "\n",
       "[984 rows x 21 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87,  3],\n",
       "       [ 9, 98]], dtype=int64)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9390862944162437"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV ( dropped scaled_amount column ) \n",
    "#### Makes no difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[ :, ~df.columns.isin(['scaled_amount', 'Class'])]#.values\n",
    "y = df.iloc[ :, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  2],\n",
       "       [ 9, 98]], dtype=int64)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441624365482234"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV ( dropped all V column ) \n",
    "#### Drastic drop in score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[ :, 0:1].values\n",
    "y = df.iloc[ :, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[84,  6],\n",
       "       [80, 27]], dtype=int64)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5634517766497462"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressionCV ( only V1 to V22 column )\n",
    "#### Accuracy remains same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[ :, 0:24].values    # 0:24 - 0.94416 ( V1 to V22)\n",
    "                                # 0:23 - 0.93401 ( V1 to V21)\n",
    "y = df.iloc[ :, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.20118218,  -1.78554051,  -1.38638048, ...,  -0.13105466,\n",
       "          0.66208381,  -0.08667123],\n",
       "       [ -0.34923131,   0.12866687, -23.98474665, ...,   5.80455066,\n",
       "        -12.61502286,   5.77408727],\n",
       "       [ -0.209898  ,   0.56465012,   0.34593206, ...,   0.17720937,\n",
       "          0.55769395,   1.4890205 ],\n",
       "       ...,\n",
       "       [ -0.09331381,  -0.14742357,  -1.60859862, ...,  -0.56740584,\n",
       "          3.46327354,   0.25171796],\n",
       "       [ -0.23348671,  -0.40553054,  -0.73430316, ...,   0.86453612,\n",
       "         -1.00487738,   1.15035359],\n",
       "       [  0.03862303,  -0.61248781,   1.22761441, ...,   0.27379921,\n",
       "         -0.02605472,  -0.29525477]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(max_iter = 10000, cv=5, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  2],\n",
       "       [ 9, 98]], dtype=int64)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441624365482234"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
